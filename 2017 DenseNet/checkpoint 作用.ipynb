{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "查看conv里面的梯度，一开始应当全为0或None\n",
      "None\n",
      "None\n",
      "查看conv里面的梯度，现在应该不为0了\n",
      "tensor([[[[0.5000]]],\n",
      "\n",
      "\n",
      "        [[[0.5000]]]])\n",
      "tensor([0.5000, 0.5000])\n",
      "清空conv的梯度，进行下一次测试\n",
      "查看conv里面的梯度，现在应该全为0了\n",
      "tensor([[[[0.]]],\n",
      "\n",
      "\n",
      "        [[[0.]]]])\n",
      "tensor([0., 0.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\py37\\lib\\site-packages\\torch\\utils\\checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "此时应当会失败，y并不是计算图的一部分，因为x的requires_grad为False，checkpoint认为这段函数是不需要计算梯度的\n",
      "backward果然抛出异常了\n",
      "查看conv里面的梯度，现在应该保持不变，仍然全为0了\n",
      "tensor([[[[0.]]],\n",
      "\n",
      "\n",
      "        [[[0.]]]])\n",
      "tensor([0., 0.])\n",
      "让输入的requires_grad为True，有俩个办法，一个是直接设定x的requires_grad为True，另外一个办法就是与另外一个requires_grad为True的常量合并操作\n",
      "这里使用的是合并操作，因为有时候并不能直接设置输入的requires_grad=True，另外我认为合并操作占用的显存更少，因为grad的shape跟原始变量是一样的，使用合并操作，额外无用的grad的size只有1，而设定输入的requires_grad为True，额外无用的grad的size跟输入一样大\n",
      "现在backward不会报错了\n",
      "查看conv里面的梯度，现在不为0了\n",
      "tensor([[[[0.5000]]],\n",
      "\n",
      "\n",
      "        [[[0.5000]]]])\n",
      "tensor([0.5000, 0.5000])\n",
      "实验完成\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "\n",
    "conv = nn.Conv2d(in_channels=1, out_channels=2, kernel_size=1)\n",
    "\n",
    "def seg1(x):\n",
    "    return conv(x)\n",
    "\n",
    "print('查看conv里面的梯度，一开始应当全为0或None')\n",
    "print(conv.weight.grad)\n",
    "print(conv.bias.grad)\n",
    "\n",
    "x = torch.ones(1, 1, 1, 1)\n",
    "y = seg1(x).mean() - 3\n",
    "y.backward()\n",
    "\n",
    "print('查看conv里面的梯度，现在应该不为0了')\n",
    "print(conv.weight.grad)\n",
    "print(conv.bias.grad)\n",
    "\n",
    "print('清空conv的梯度，进行下一次测试')\n",
    "conv.weight.grad.data.zero_()\n",
    "conv.bias.grad.data.zero_()\n",
    "\n",
    "print('查看conv里面的梯度，现在应该全为0了')\n",
    "print(conv.weight.grad)\n",
    "print(conv.bias.grad)\n",
    "\n",
    "y = checkpoint(seg1, x).mean() - 3\n",
    "try:\n",
    "    print('此时应当会失败，y并不是计算图的一部分，因为x的requires_grad为False，checkpoint认为这段函数是不需要计算梯度的')\n",
    "    y.backward()\n",
    "except RuntimeError as e:\n",
    "    print('backward果然抛出异常了')\n",
    "\n",
    "print('查看conv里面的梯度，现在应该保持不变，仍然全为0了')\n",
    "print(conv.weight.grad)\n",
    "print(conv.bias.grad)\n",
    "\n",
    "print('让输入的requires_grad为True，有俩个办法，一个是直接设定x的requires_grad为True，另外一个办法就是与另外一个requires_grad为True的常量合并操作')\n",
    "print('这里使用的是合并操作，因为有时候并不能直接设置输入的requires_grad=True，另外我认为合并操作占用的显存更少，因为grad的shape跟原始变量是一样的'\n",
    "      '，使用合并操作，额外无用的grad的size只有1，而设定输入的requires_grad为True，额外无用的grad的size跟输入一样大')\n",
    "x2 = x + torch.zeros(1, dtype=x.dtype, device=x.device, requires_grad=True)\n",
    "y = checkpoint(seg1, x2).mean() - 3\n",
    "y.backward()\n",
    "print('现在backward不会报错了')\n",
    "print('查看conv里面的梯度，现在不为0了')\n",
    "print(conv.weight.grad)\n",
    "print(conv.bias.grad)\n",
    "print('实验完成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37] *",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
